Questions

Please write a short response (4-5 sentences / short paragraph) to
each of the following questions / the following question. Your
responses will be graded for accuracy, critical thinking, and
clarity. You may use any common word processing or text format. Please
upload your answers by the due date.

Question 1: Explain the concept of a tensor, and the differences in PyTorch between a tensor, a
parameter, and a gradient.

A tensor is much like an array: at it's core it's a container for lots of values, kind of like a list. Like a numpy array, a tensor is organized into n-dimensions, which means they can be organized into rows, columns, and the n-dimensional equivalent to those (for example, a tensor and a numpy array can be of the shape (64, 128, 128, 1024), which means that they can have 64 objects along dimension 0, 128 objects along dimension 1, and so on).

What makes a tensor different from a numpy array is that they can also contain information about the computational graph and the gradients flowing along that graph. In essence, it's like a numpy array that can be aware of what other numpy arrays it's connected to. On top of this, tensors are engineered to be compatible with GPUs, which means that very large parallelizable operations can leverage the very fast speed of GPUs, unlike numpy which is driven by CPU computations.

A "parameter", in pytorch, is a subclass type of tensor which is used in neural networks, whose primary difference is that it also keeps track of a gradient. That is, it's a tensor whose value is expected to be changed based on how it's connected to other parameters, kind of like an array with additional context. You can also track a gradient in a tensor with the "requires_grad=True" argument, but parameters are also automatically followed by an optimizer, whereas a tensor is not by default. That is, it's a big abstraction around tensor which makes it a little more convenient for a neural network in particular. A network's parameters are what gets changed during training based on your provided dataset. You can organize these parameters together to create layers of a neural network.

The way it does this is by following the gradient of each parameter. What makes these networks "go" is the fact that they all optimize a loss function which must be differentiable, usually something like cross-entropy loss. When a network produces some output, we can use this loss function in order to measure how far away the output was from the correct answer. In order to train our network, we want to change our parameters every time we see a new input to go a little bit in the direction of the correct answer (that is, a very small number "learning rate", multiplied by the "right way, in the direction of the right answer" for each parameter). This "right way" is the gradient, i.e. the direction the loss function decreases the fastest, which is the partial derivative of the loss function with respect to each parameter. You can compute the gradient using the chain rule from differential calculus. This is pretty tedious to do by hand, but pytorch luckily takes care of this all for us with autograd.
